{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "To prepare our data for use by our neural net, we first needed to split it into groups of data that follow specific rules. To streamline the process, we used the `Dataset` class to store and manage our input data. This class was responsible for splitting the data into strings of the correct length and for turning them into one hot encoded arrays that the neural net could better understand. We stored this pre-prepared data in a `Batch` object, which has `inputs` and `targets` attributes for our model to use in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, seqs):\n",
    "        \"\"\"Create a batch using the sequence\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "            seqs: int[][]\n",
    "                The one-hot encoded sequences.\n",
    "        \"\"\"\n",
    "        self.inputs = [seq[:-1] for seq in seqs]\n",
    "        self.targets = [seq[1:] for seq in seqs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(\n",
    "            self,\n",
    "            filenames,\n",
    "            seq_length,\n",
    "            shuffle=True,\n",
    "            buffer_size=10000,\n",
    "    ):\n",
    "        \"\"\"Creates a dataset\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "            filenames: string\n",
    "                Path to one or more plain text files.\n",
    "                The file contents are concatenated in the given order.\n",
    "\n",
    "            seq_length: int\n",
    "                The length of the text sequence.\n",
    "\n",
    "            shuffle: boolean\n",
    "                Whether to shuffle the sequences for the batches.\n",
    "\n",
    "            buffer_size: int\n",
    "                 The number of elements from this dataset from which the new\n",
    "                 dataset will sample.\n",
    "        \"\"\"\n",
    "        text = ''\n",
    "        vocab = set()\n",
    "        for filename in filenames:\n",
    "            content = open(filename).read()\n",
    "            text += content\n",
    "            vocab = vocab.union(set(content))\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = len(vocab)\n",
    "        self.char_to_ix = {c: i for i, c in enumerate(vocab)}\n",
    "        self.ix_to_char = list(vocab)\n",
    "        self.text = text\n",
    "        self.data = np.array([self.char_to_ix[c] for c in text])\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def batch(\n",
    "            self,\n",
    "            batch_size,\n",
    "            drop_remainder=True\n",
    "    ):\n",
    "        \"\"\"Batch the instances\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "            batch_size: int\n",
    "                The number of instances in a single batch.\n",
    "\n",
    "            drop_remainder: boolean\n",
    "                Whether the last batch should be dropped in the case its has\n",
    "                fewer than batch_size elements.\n",
    "        \"\"\"\n",
    "        n_seq = len(self.data) // self.seq_length\n",
    "        n_batch = n_seq // batch_size\n",
    "        seq_ids = np.arange(n_seq)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(seq_ids)\n",
    "        i = 0\n",
    "        for _ in range(n_batch):\n",
    "            seqs = [None] * batch_size\n",
    "            for j in range(batch_size):\n",
    "                k = seq_ids[i] * self.seq_length\n",
    "                seqs[j] = self._create_seq(k, k + self.seq_length + 1)\n",
    "                i += 1\n",
    "            yield Batch(seqs)\n",
    "        if not drop_remainder:\n",
    "            seqs = []\n",
    "            for j in range(n_seq % batch_size):\n",
    "                k = seq_ids[i] * self.seq_length\n",
    "                seqs[j] = self._create_seq(k, k + self.seq_length + 1)\n",
    "                i += 1\n",
    "            yield Batch(seqs)\n",
    "\n",
    "    def _create_seq(self, i, j):\n",
    "        return list(map(self._to_label, self.data[i:j]))\n",
    "\n",
    "    def _to_label(self, index):\n",
    "        label = np.zeros(self.vocab_size)\n",
    "        label[index] = 1.0\n",
    "        return label\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"One-hot encode the text\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "            text: string\n",
    "                The text to encode.\n",
    "\n",
    "        Returns\n",
    "        ======================================================================\n",
    "            seq: int[]\n",
    "                The one-hot encoded sequence.\n",
    "        \"\"\"\n",
    "        return [self._to_label(self.char_to_ix[c]) for c in text]\n",
    "\n",
    "    def decode(self, seq):\n",
    "        \"\"\"Decode the one-hot encoded sequence to text format\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "            text: string\n",
    "                The text to encode.\n",
    "\n",
    "        Returns\n",
    "        ======================================================================\n",
    "            seq: int[]\n",
    "                The one-hot encoded sequence.\n",
    "        \"\"\"\n",
    "        text = ''\n",
    "        for label in seq:\n",
    "            text += self.ix_to_char[np.argmax(label)]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text generator itself is stored in the `RNNTextGenerator` class. Among other things, storing the generator in the class allows the session to be stored and used again and prevents accidental loss of information. It also allows multiple generators to exist simultaniously for testing or training with different data. \n",
    "\n",
    "The class also internalizes the methods needed to save and restore a model, allowing the generator to pick up where it previously left off.\n",
    "\n",
    "The text generator does not take batches when training, however, and needs to be fed the inputs and targets seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTextGenerator:\n",
    "    \"\"\"A text generator using basic cell and dynamic rnn\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            seq_length,\n",
    "            vocab_size,\n",
    "            rnn_cell=tf.nn.rnn_cell.BasicRNNCell,\n",
    "            n_neurons=100,\n",
    "            optimizer=tf.train.AdamOptimizer,\n",
    "            learning_rate=0.001,\n",
    "            name='RNNTextGenerator',\n",
    "            logdir=None\n",
    "    ):\n",
    "        \"\"\"Initialize the text generator and contruct the tf graph\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "        seq_length: int\n",
    "            The number of characters in a sequence.\n",
    "\n",
    "        vocab_size: int\n",
    "            The number of unique characters in the text.\n",
    "\n",
    "        rnn_cell: tf.nn.rnn_cell.*\n",
    "            A rnn cell from tensorflow.\n",
    "\n",
    "        n_neurons: int\n",
    "            The number of neurons in each RNN cell.\n",
    "\n",
    "        optimizer: tf.train.*Optimizer\n",
    "            An optimizer from tensorflow.\n",
    "\n",
    "        learning_rate:\n",
    "            A Tensor or a floating point value. The learning rate of the\n",
    "            optimizer.\n",
    "\n",
    "        name: string\n",
    "            The name of the net (for graph visualization in tensorboard).\n",
    "\n",
    "        logdir: string\n",
    "            The path to save the tensorflow summary.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.tf_graph = tf.Graph()\n",
    "        with self.tf_graph.as_default():\n",
    "            self.tf_sess = tf.Session()\n",
    "            # One-hot encoded input and targets\n",
    "            \"\"\"placeholder\n",
    "            Example\n",
    "            [\n",
    "                batch_0: [\n",
    "                    seq_0: [\n",
    "                        # encoded labels with 5 categories\n",
    "                        [0, 0, 0, 1, 0],  # i = 0\n",
    "                        [0, 0, 1, 0, 0],  # i = 1\n",
    "                    ],\n",
    "                    ...\n",
    "                ],\n",
    "                ...\n",
    "            ]\n",
    "            \"\"\"\n",
    "            self.tf_input = tf.placeholder(\n",
    "                tf.float32, shape=(None, seq_length, vocab_size)\n",
    "            )\n",
    "            self.tf_target = tf.placeholder(\n",
    "                tf.float32, shape=(None, seq_length, vocab_size)\n",
    "            )\n",
    "            with tf.variable_scope(name):\n",
    "                self.tf_rnn_cell = rnn_cell(n_neurons)\n",
    "                outputs, _ = tf.nn.dynamic_rnn(\n",
    "                    self.tf_rnn_cell,\n",
    "                    tf.cast(self.tf_input, tf.float32),\n",
    "                    dtype=tf.float32,\n",
    "                )\n",
    "                logits = tf.layers.dense(outputs, vocab_size)\n",
    "                self.tf_loss = tf.reduce_mean(\n",
    "                    tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                        logits=logits,\n",
    "                        labels=self.tf_target,\n",
    "                    )\n",
    "                )\n",
    "                self.tf_train = optimizer(\n",
    "                    learning_rate=learning_rate\n",
    "                ).minimize(self.tf_loss)\n",
    "                self.tf_prob = tf.nn.softmax(logits)\n",
    "                self.tf_acc = tf.reduce_mean(tf.cast(\n",
    "                    tf.equal(\n",
    "                        tf.argmax(logits, 2),\n",
    "                        tf.argmax(self.tf_target, 2),\n",
    "                    ),\n",
    "                    tf.float32\n",
    "                ))\n",
    "                self.tf_saver = tf.train.Saver()\n",
    "                if logdir is not None:\n",
    "                    self.logger = tf.summary.FileWriter(logdir, self.tf_graph)\n",
    "            # Initialize the tf session\n",
    "            self.tf_sess.run(tf.global_variables_initializer())\n",
    "            self.tf_sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    def fit(self, dataset, epoch, batch_size):\n",
    "        \"\"\"Fit and train the classifier with a batch of inputs and targets\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "        inputs: np.ndarray\n",
    "            A batch of input sequences.\n",
    "\n",
    "        targets: np.ndarray\n",
    "            A batch of target sequences.\n",
    "        \"\"\"\n",
    "        for _ in range(epoch):\n",
    "            for batch in dataset.batch(batch_size):\n",
    "                self.tf_sess.run(\n",
    "                    self.tf_train,\n",
    "                    feed_dict={\n",
    "                        self.tf_input: batch.inputs,\n",
    "                        self.tf_target: batch.targets,\n",
    "                    },\n",
    "                )\n",
    "        return self\n",
    "\n",
    "    def score(self, inputs, targets):\n",
    "        \"\"\"Get the score for the batch\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "        inputs: np.ndarray\n",
    "            A batch of input sequences.\n",
    "\n",
    "        targets: np.ndarray\n",
    "            A batch of target sequences.\n",
    "\n",
    "        Returns\n",
    "        ======================================================================\n",
    "        accuracy: tf.float32\n",
    "            The accuracy on this batch.\n",
    "\n",
    "        loss: tf.float32\n",
    "            The loss on this batch.\n",
    "        \"\"\"\n",
    "        return self.tf_sess.run(\n",
    "            [self.tf_acc, self.tf_loss],\n",
    "            feed_dict={\n",
    "                self.tf_input: inputs,\n",
    "                self.tf_target: targets,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"Predict the probablities for the labels, for a batch of inputs\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "        inputs: np.ndarray\n",
    "            A batch of input sequences.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ======================================================================\n",
    "        predictions: np.ndarray\n",
    "            A batch of sequences of probablities.\n",
    "        \"\"\"\n",
    "        return self.tf_sess.run(\n",
    "            self.tf_prob,\n",
    "            feed_dict={\n",
    "                self.tf_input: inputs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def save(self, path='./model'):\n",
    "        \"\"\"Save the model\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "        path: string\n",
    "            The path to store the model.\n",
    "        \"\"\"\n",
    "        self.tf_saver.save(\n",
    "            self.tf_sess,\n",
    "            path + '/' + self.name\n",
    "        )\n",
    "\n",
    "    def restore(self, path='./model'):\n",
    "        \"\"\"Restore the model\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "        path: string\n",
    "            The path where the model is saved.\n",
    "        \"\"\"\n",
    "        self.tf_saver.restore(\n",
    "            self.tf_sess,\n",
    "            path + '/' + self.name\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def sample(model, dataset, start_seq, length):\n",
    "        \"\"\"Generate the text using a saved model\n",
    "        Arguments\n",
    "        ======================================================================\n",
    "        model: RNNTextGenerator\n",
    "            The model to sample from.\n",
    "\n",
    "        dataset: Dataset\n",
    "            The dataset to encode and decode the labels.\n",
    "\n",
    "        start_seq: string\n",
    "            The character sequence to begin with.\n",
    "\n",
    "        length: int\n",
    "            The length of the generated text.\n",
    "\n",
    "        Returns\n",
    "        ======================================================================\n",
    "        text: string\n",
    "            The generated text.\n",
    "        \"\"\"\n",
    "        text = [None] * length\n",
    "        seq = dataset.encode(start_seq)\n",
    "        for i in range(length):\n",
    "            ix = np.random.choice(\n",
    "                range(dataset.vocab_size),\n",
    "                # pred[batch 0][last item in the sequence]\n",
    "                p=model.predict([seq])[0][-1]\n",
    "            )\n",
    "            x = np.zeros(dataset.vocab_size)\n",
    "            x[ix] = 1\n",
    "            del seq[0]\n",
    "            seq.append(x)\n",
    "            text[i] = x\n",
    "        return dataset.decode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the dataset generator\n",
    "To test our dataset generator, we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Testing Dataset generator-----------\n"
     ]
    }
   ],
   "source": [
    "def test_batch_a_seq():\n",
    "        print(\"-----------Testing Dataset generator-----------\")\n",
    "        batch_size = 5\n",
    "        seq_length = 100\n",
    "        filename = '../data/alice.txt'\n",
    "        dataset = Dataset([filename], seq_length)\n",
    "        for batch in dataset.batch(batch_size):\n",
    "            assert(len(batch.inputs) == batch_size)\n",
    "            assert(len(batch.targets) == batch_size)\n",
    "            assert(len(batch.inputs[-1]) == seq_length)\n",
    "            assert(len(batch.targets[-1]) == seq_length)\n",
    "            assert(sum(batch.inputs[1][1]) == 1)\n",
    "test_batch_a_seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the text generator\n",
    "Before using any neural net, it's importamt to make sure that it is correctly processing the data it is given. To make sure this is the case, we fed our text generator some randomly generated data. While a fresh model will be needed to train on the text, this model is used to verify that the code is working correctly.\n",
    "In this case, we are checking to ensure the model is providing sufficient variance in its outputs. This shows that the model is opperating on its inputs and successfully completing its operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_label(vocab_size):\n",
    "    \"\"\"randomly assign a label\n",
    "    \"\"\"\n",
    "    label = np.random.randint(vocab_size)\n",
    "    seq = np.zeros(vocab_size)\n",
    "    seq[label] = 1.0\n",
    "    return seq\n",
    "\n",
    "\n",
    "def random_data(batch_size, seq_length, vocab_size):\n",
    "    \"\"\"generate random data\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for _ in range(batch_size):\n",
    "        labels = [random_label(vocab_size) for _ in range(seq_length + 1)]\n",
    "        inputs.append(labels[:-1])\n",
    "        targets.append(labels[1:])\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "def test_on_random_data():\n",
    "    print(\"---------------Testing text generator with randomly generated data-------------\")\n",
    "    seq_length = 10\n",
    "    vocab_size = 4\n",
    "    batch_size = 2\n",
    "    text_gen = RNNTextGenerator(\n",
    "        seq_length,\n",
    "        vocab_size,\n",
    "    )\n",
    "    print('first fit')\n",
    "    inputs, targets = random_data(batch_size, seq_length, vocab_size)\n",
    "    print('fit:', text_gen.fit(inputs, targets))\n",
    "    print('score:', text_gen.score(inputs, targets))\n",
    "    print('predictions:', text_gen.predict(inputs))\n",
    "    print('true targets:', targets)\n",
    "    text_gen.save()\n",
    "\n",
    "    seq_length = 5\n",
    "    text_gen = RNNTextGenerator(\n",
    "        seq_length,\n",
    "        vocab_size\n",
    "    )\n",
    "    text_gen.restore()\n",
    "\n",
    "def test_log():\n",
    "    print(\"-------------Testing logs---------------\")\n",
    "    seq_length = 10\n",
    "    vocab_size = 4\n",
    "    batch_size = 2\n",
    "    text_gen = RNNTextGenerator(\n",
    "        seq_length,\n",
    "        vocab_size,\n",
    "        logdir='./tf_logs'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Testing text generator with randomly generated data-------------\n",
      "WARNING:tensorflow:From <ipython-input-4-396a028e528c>:56: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-396a028e528c>:66: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-396a028e528c>:74: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "first fit\n",
      "fit: <__main__.RNNTextGenerator object at 0x7f0e46ba9f28>\n",
      "score: [0.35, 1.3485482]\n",
      "predictions: [[[0.24663274 0.23564416 0.24870843 0.26901466]\n",
      "  [0.30227402 0.23291834 0.19896173 0.26584592]\n",
      "  [0.24170421 0.26695326 0.23870343 0.25263914]\n",
      "  [0.21038045 0.24317619 0.28113458 0.26530874]\n",
      "  [0.2998881  0.17778748 0.21018948 0.31213495]\n",
      "  [0.17003703 0.25019705 0.30076247 0.27900347]\n",
      "  [0.23931229 0.30753118 0.26230004 0.19085655]\n",
      "  [0.2413353  0.2617463  0.22470272 0.27221566]\n",
      "  [0.17340143 0.33572182 0.3085556  0.18232118]\n",
      "  [0.2788699  0.28509066 0.12944171 0.30659783]]\n",
      "\n",
      " [[0.2249938  0.26330534 0.27266747 0.23903342]\n",
      "  [0.21359827 0.24828792 0.28553116 0.25258264]\n",
      "  [0.22399388 0.2557768  0.29564267 0.2245867 ]\n",
      "  [0.17621115 0.31834817 0.23408216 0.27135858]\n",
      "  [0.21100408 0.30081552 0.21444225 0.2737382 ]\n",
      "  [0.21201336 0.25688583 0.2700306  0.26107028]\n",
      "  [0.24030292 0.2837045  0.20223883 0.27375382]\n",
      "  [0.22582373 0.2924031  0.19159046 0.29018274]\n",
      "  [0.25994357 0.23329645 0.20443441 0.30232558]\n",
      "  [0.26953608 0.30434203 0.1177544  0.3083675 ]]]\n",
      "true targets: [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]]]\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      "-------------Testing logs---------------\n"
     ]
    }
   ],
   "source": [
    "test_on_random_data()\n",
    "test_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the model'spredictions as to what the target are have sufficient variance so as to provide seemingly random probabilities of each output. This suggests that the model, while in need of training, is making its predictions appropriatly.\n",
    "\n",
    "We also verified that tensorflow's logs were being stored in the correct location, as that is also managed by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "A short amount of training provides us with a model that is capable of forming multiple words and a few phrases, but not much more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Testing dataset Alice---------------\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      ">>>>> hello w!'\n",
      "\n",
      "Shrintion?' said--'Wowave, she way's begs, and she tole some\n",
      "wite, were in a hesstoroused bearmadrationst's a on a but I'tep. The\n",
      "certening, shill at this begin the execumbith squeer leep a moring hand of outer alarm--'\n",
      "\n",
      "'Why your at lings of liks!'\n",
      "\n",
      "'Whysomed me to might the Queens had no bagen in ale tring happensis,t the helf quite\n",
      "Raid Alice,' said,\n",
      "went thes?' shuse were outhing; 'bos a littled veep at \"Every! Here to gack aliay, nis, now one cat! Nave your somer,' shade--in out nexch,\n",
      "<<<<<<\n"
     ]
    }
   ],
   "source": [
    "\"\"\"An end to end test using \n",
    " ALICE'S ADVENTURES IN WONDERLAND\n",
    "\"\"\"\n",
    "print(\"----------------Testing dataset Alice---------------\")\n",
    "seq_length = 25\n",
    "batch_size = 25\n",
    "learning_rate = 0.01\n",
    "epoch = 10\n",
    "dataset = Dataset(['../data/alice.txt'], seq_length)\n",
    "model = RNNTextGenerator(\n",
    "    seq_length,\n",
    "    dataset.vocab_size,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "for _ in range(epoch):\n",
    "    for batch in dataset.batch(batch_size):\n",
    "        model.fit(batch.inputs, batch.targets)\n",
    "model.save()\n",
    "\n",
    "start_seq = 'hello'\n",
    "model = RNNTextGenerator(\n",
    "    len(start_seq),\n",
    "    dataset.vocab_size,\n",
    ")\n",
    "\n",
    "model.restore()\n",
    "print('>>>>> {}'.format(start_seq), RNNTextGenerator.sample(\n",
    "    model,\n",
    "    dataset,\n",
    "    start_seq,\n",
    "    500\n",
    "))\n",
    "print('<<<<<<')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long term training:\n",
    "We then continued to train the same model on our dataset to see how well our model learned when it continued to be fed data from its dataset. \n",
    "\n",
    "Every 20 epochs, we paused training to test our model before resuming training. As well as generating texts that can be used for subjective scoring of a model, the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(\n",
    "    dataset,\n",
    "    learning_rate,\n",
    "    start_seed,\n",
    "    model_name = \"RNNTextGenerator\",\n",
    "    model_exists = True,\n",
    "    train_seq_length = 25,\n",
    "    epoch = 20,\n",
    "    time = 0\n",
    "    ):\n",
    "    \n",
    "    while(True):\n",
    "        #build model to train on\n",
    "        model = RNNTextGenerator(\n",
    "            train_seq_length,\n",
    "            dataset.vocab_size,\n",
    "            learning_rate=learning_rate,\n",
    "            name=model_name,\n",
    "        )\n",
    "        if (model_exists):\n",
    "            model.restore()\n",
    "        #train\n",
    "        for _ in range(epoch):\n",
    "            for batch in dataset.batch(batch_size):\n",
    "                model.fit(batch.inputs, batch.targets)\n",
    "        model.save()\n",
    "        model_exists = True\n",
    "        #Build model to sample with\n",
    "        model = RNNTextGenerator(\n",
    "            len(start_seed),\n",
    "        dataset.vocab_size,\n",
    "        )\n",
    "        model.restore()\n",
    "        #Sample stuff\n",
    "        print('>>>>> {}'.format(start_seed), RNNTextGenerator.sample(\n",
    "            model,\n",
    "            dataset,\n",
    "            start_seed,\n",
    "            50\n",
    "        ))\n",
    "        print('<<<<<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      ">>>>> .\n",
      " \n",
      "'At and bt ied ther hat\n",
      "         thmarle Qaidefbl\n",
      "<<<<<<\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      ">>>>> .\n",
      " \n",
      "''se sioell wowme rithoyere; Ir tr was the the li\n",
      "<<<<<<\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      ">>>>> .\n",
      " \n",
      "ThERY hou kout, what isand of   Herfpais read bne\n",
      "<<<<<<\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      ">>>>> .\n",
      " \n",
      "'Ssowemarlmme'ged e brt\n",
      "yat. ' Anlancomy therping\n",
      "<<<<<<\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      ">>>>> .\n",
      " \n",
      "'The soesn 'and. Alis\n",
      "and ne int, Alit iteess, IA\n",
      "<<<<<<\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      ">>>>> .\n",
      " \n",
      "'Yef tomeinht     avead fight she dualloexken was\n",
      "<<<<<<\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n",
      ">>>>> .\n",
      " \n",
      "'noid womm, tho, fings\n",
      "erewask, to theryous eoped\n",
      "<<<<<<\n",
      "INFO:tensorflow:Restoring parameters from ./model/RNNTextGenerator\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cb62cb73febc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-cb4444eaf671>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(dataset, learning_rate, start_seed, model_exists, train_seq_length, epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-396a028e528c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m    101\u001b[0m             feed_dict={\n\u001b[1;32m    102\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             },\n\u001b[1;32m    105\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_test(dataset = dataset, learning_rate = learning_rate, start_seed = \".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
